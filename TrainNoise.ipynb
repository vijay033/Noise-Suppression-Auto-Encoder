{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy.stats import norm\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "import IPython.display\n",
    "from ipywidgets import interact, interactive, fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import IPython.display\n",
    "from ipywidgets import interact, interactive, fixed\n",
    "\n",
    "# Packages we're using\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "from scipy.io import wavfile\n",
    "from scipy.signal import butter, lfilter\n",
    "import scipy.ndimage\n",
    "\n",
    "import glob\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "# plt, plot, tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages we're using\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "from scipy.io import wavfile\n",
    "from scipy.signal import butter, lfilter\n",
    "import scipy.ndimage\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from PIL import Image\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train = './train'\n",
    "path_test = './test'\n",
    "path_ytrain = './y_train'\n",
    "path_ytest = './y_test'\n",
    "\n",
    "path_mat_train = './mat_train'\n",
    "path_mat_test = './mat_test'\n",
    "path_mat_ytrain = './mat_ytrain'\n",
    "path_mat_ytest = './mat_ytest'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROW = 257\n",
    "COL = 62"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(257, 62)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INPUT_DIM = (ROW,COL,3)\n",
    "INPUT_DIM[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import gzip\n",
    "%matplotlib inline\n",
    "from keras.layers import Input,Conv2D,MaxPooling2D,UpSampling2D,concatenate\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Dropout\n",
    "from keras.models import Model\n",
    "from keras.optimizers import RMSprop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "FFT_LENGTH = 512\n",
    "WINDOW_LENGTH = 512\n",
    "WINDOW_STEP = int(WINDOW_LENGTH / 2)\n",
    "\n",
    "phaseMax = 3.141592653589793 \n",
    "phaseMin = -3.141592653589793\n",
    "magnitudeMax = 2211683.973249525\n",
    "magnitudeMin = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def amplifyMagnitudeByLog(d):\n",
    "    return 188.301 * math.log10(d + 1)\n",
    "\n",
    "def weakenAmplifiedMagnitude(d):\n",
    "    return math.pow(10, d/188.301)-1\n",
    "\n",
    "def generateLinearScale(magnitudePixels, phasePixels, \n",
    "                        magnitudeMin, magnitudeMax, phaseMin, phaseMax):\n",
    "    height = magnitudePixels.shape[0]\n",
    "    width = magnitudePixels.shape[1]\n",
    "    magnitudeRange = magnitudeMax - magnitudeMin\n",
    "    phaseRange = phaseMax - phaseMin\n",
    "    rgbArray = np.zeros((height, width, 3), 'uint8')\n",
    "    \n",
    "    for w in range(width):\n",
    "        for h in range(height):\n",
    "            magnitudePixels[h,w] = (magnitudePixels[h,w] - magnitudeMin) / (magnitudeRange) * 255 * 2\n",
    "            magnitudePixels[h,w] = amplifyMagnitudeByLog(magnitudePixels[h,w])\n",
    "            phasePixels[h,w] = (phasePixels[h,w] - phaseMin) / (phaseRange) * 255\n",
    "            red = 255 if magnitudePixels[h,w] > 255 else magnitudePixels[h,w]\n",
    "            green = (magnitudePixels[h,w] - 255) if magnitudePixels[h,w] > 255 else 0\n",
    "            blue = phasePixels[h,w]\n",
    "            rgbArray[h,w,0] = int(red)\n",
    "            rgbArray[h,w,1] = int(green)\n",
    "            rgbArray[h,w,2] = int(blue)\n",
    "    return rgbArray\n",
    "\n",
    "def recoverLinearScale(rgbArray, magnitudeMin, magnitudeMax, \n",
    "                       phaseMin, phaseMax):\n",
    "    width = rgbArray.shape[1]\n",
    "    height = rgbArray.shape[0]\n",
    "#     print(phaseMax,phaseMin)\n",
    "    magnitudeVals = rgbArray[:,:,0].astype(float) + rgbArray[:,:,1].astype(float)\n",
    "    phaseVals = rgbArray[:,:,2].astype(float)\n",
    "    phaseRange = phaseMax - phaseMin\n",
    "    magnitudeRange = magnitudeMax - magnitudeMin\n",
    "    \n",
    "#     print(magnitudeVals)\n",
    "#     print(phaseVals)\n",
    "#     print(phaseRange)\n",
    "#     print(magnitudeRange)\n",
    "    \n",
    "    for w in range(width):\n",
    "        for h in range(height):\n",
    "            phaseVals[h,w] = (phaseVals[h,w] / 255 * phaseRange) + phaseMin\n",
    "            magnitudeVals[h,w] = weakenAmplifiedMagnitude(magnitudeVals[h,w])\n",
    "            magnitudeVals[h,w] = (magnitudeVals[h,w] / (255*2) * magnitudeRange) + magnitudeMin\n",
    "    return magnitudeVals, phaseVals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recoverSignalFromSpectrogram(numpyarray):\n",
    "#     img = Image.open(filePath)\n",
    "    data = np.array( numpyarray, dtype='uint8' )\n",
    "    width = data.shape[1]\n",
    "    height = data.shape[0]\n",
    "    \n",
    "#     print(phaseMax,phaseMin)\n",
    "\n",
    "    magnitudeVals, phaseVals \\\n",
    "    = recoverLinearScale(data, magnitudeMin, magnitudeMax, phaseMin, phaseMax)\n",
    "    \n",
    "#     print(magnitudeVals,phaseVals)\n",
    "    \n",
    "    recovered = np.zeros(WINDOW_LENGTH * width // 2 + WINDOW_STEP, dtype=np.int16)\n",
    "    recovered = np.array(recovered,dtype=np.int16)\n",
    "    \n",
    "    for w in range(width):\n",
    "        toInverse = np.zeros(height, dtype=np.complex_)\n",
    "        for h in range(height):\n",
    "            magnitude = magnitudeVals[height-h-1,w]\n",
    "            phase = phaseVals[height-h-1,w]\n",
    "            toInverse[h] = magnitude * math.cos(phase) + (1j * magnitude * math.sin(phase))\n",
    "        signal = np.fft.irfft(toInverse)\n",
    "        recovered[w*WINDOW_STEP:w*WINDOW_STEP + WINDOW_LENGTH] += signal[:WINDOW_LENGTH].astype(np.int16)\n",
    "    return recovered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_train_samples = 7000 # change here\n",
    "nb_test_samples = 105\n",
    "\n",
    "train_batch_size = [5,4,3,2]\n",
    "test_batch_size = [5,4,3,2]\n",
    "\n",
    "epochs = 30\n",
    "inChannel = 3\n",
    "x, y = INPUT_DIM[:2]\n",
    "input_img = Input(shape = (x, y, inChannel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7000/7000 [00:00<00:00, 389950.17it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7000/7000 [00:00<00:00, 502286.08it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 105/105 [00:00<?, ?it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 105/105 [00:00<00:00, 105283.75it/s]\n"
     ]
    }
   ],
   "source": [
    "train_image = []\n",
    "path = path_mat_train\n",
    "for filename in tqdm(glob.glob(os.path.join(path, '*.npy'))):\n",
    "    train_image.append(os.path.join(filename))\n",
    "    \n",
    "ytrain_image = []\n",
    "path = path_mat_ytrain\n",
    "for filename in tqdm(glob.glob(os.path.join(path, '*.npy'))):\n",
    "    ytrain_image.append(os.path.join(filename))\n",
    "    \n",
    "test_image = []\n",
    "path = path_mat_test\n",
    "for filename in tqdm(glob.glob(os.path.join(path, '*.npy'))):\n",
    "    test_image.append(os.path.join(filename))\n",
    "    \n",
    "ytest_image = []\n",
    "path = path_mat_ytest\n",
    "for filename in tqdm(glob.glob(os.path.join(path, '*.npy'))):\n",
    "    ytest_image.append(os.path.join(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./mat_train\\103-1240-0005.npy ./mat_ytrain\\103-1240-0005.npy\n"
     ]
    }
   ],
   "source": [
    "print(train_image[0],ytrain_image[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./mat_test\\1034-121119-0049.npy ./mat_ytest\\1034-121119-0049.npy\n"
     ]
    }
   ],
   "source": [
    "print(test_image[0],ytest_image[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_gen_train(train_batch_size):\n",
    "    while True:\n",
    "        for start in range(0,nb_train_samples,train_batch_size):\n",
    "            x_batch = []\n",
    "            y_batch = []\n",
    "            end = min(start + train_batch_size, nb_train_samples)\n",
    "            for img_path in range(start, end):\n",
    "                img_train = np.load(train_image[img_path])\n",
    "                img_train = img_train/255\n",
    "                x_batch.append(img_train)\n",
    "                img_ytrain = np.load(ytrain_image[img_path])\n",
    "                img_ytrain = img_ytrain/255\n",
    "                y_batch.append(img_ytrain)\n",
    "            yield (np.array(x_batch), np.array(y_batch)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_gen_test(test_batch_size):\n",
    "    while True:\n",
    "        for start in range(0,nb_test_samples,test_batch_size):\n",
    "            x_batch = []\n",
    "            y_batch = []\n",
    "            end = min(start + test_batch_size, nb_test_samples)\n",
    "            for img_path in range(start, end):\n",
    "                img_test = np.load(test_image[img_path])\n",
    "                img_test = img_test/255\n",
    "                x_batch.append(img_test)\n",
    "                img_ytest= np.load(ytest_image[img_path])\n",
    "                img_ytest = img_ytest/255\n",
    "                y_batch.append(img_ytest)\n",
    "            yield (np.array(x_batch), np.array(y_batch)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Architecture 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not using this architecture\n",
    "# Attempt to reduce network size, latency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autoencoder(input_img):\n",
    "    #encoder\n",
    "    conv1 = Conv2D(32, (2, 2), strides=(1, 1), activation='relu', padding='same')(input_img)\n",
    "    pool1 = MaxPooling2D(pool_size=(1, 1))(conv1)\n",
    "    pool1 = Dropout(0.5)(pool1)\n",
    "    conv2 = Conv2D(64, (2, 2), strides=(1, 1), activation='relu', padding='same')(pool1)\n",
    "    pool2 = MaxPooling2D(pool_size=(1, 1))(conv2)\n",
    "    pool2 = Dropout(0.5)(pool2)\n",
    "    conv3 = Conv2D(128, (2, 2), strides=(1, 1), activation='relu', padding='same')(pool2)\n",
    "    pool3 = MaxPooling2D(pool_size=(1, 1))(conv3)\n",
    "    pool3 = Dropout(0.5)(pool3)\n",
    "    conv4 = Conv2D(256, (2, 2), strides=(1, 1), activation='relu', padding='same')(pool3)\n",
    "    \n",
    "    #decoder\n",
    "    conv5 = Conv2D(256, (2, 2),strides=(1, 1), activation='relu', padding='same')(conv4)\n",
    "    skip1 = concatenate([conv5, conv4], name='skip1')\n",
    "    up1 = UpSampling2D((1,1))(skip1)\n",
    "    up1 = Dropout(0.5)(up1)\n",
    "    conv6 = Conv2D(128, (2, 2),strides=(1, 1), activation='relu', padding='same')(conv5)\n",
    "    skip2 = concatenate([conv6, conv3], name='skip2')\n",
    "    up2 = UpSampling2D((1,1))(skip2)\n",
    "    up2 = Dropout(0.5)(up2)\n",
    "    conv7 = Conv2D(64, (2, 2),strides=(1, 1), activation='relu', padding='same')(up2)\n",
    "    skip3 = concatenate([conv7, conv2], name='skip3')\n",
    "    up3 = UpSampling2D((1,1))(skip3)\n",
    "    up3 = Dropout(0.5)(up3)\n",
    "    decoded = Conv2D(3, (2, 2),strides=(1, 1), activation='sigmoid', padding='same')(up3)\n",
    "    return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 257, 62, 3)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 257, 62, 32)  416         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 257, 62, 32)  0           conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 257, 62, 32)  0           max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 257, 62, 64)  8256        dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 257, 62, 64)  0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 257, 62, 64)  0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 257, 62, 128) 32896       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 257, 62, 128) 0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 257, 62, 128) 0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 257, 62, 256) 131328      dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 257, 62, 256) 262400      conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 257, 62, 128) 131200      conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "skip2 (Concatenate)             (None, 257, 62, 256) 0           conv2d_5[0][0]                   \n",
      "                                                                 conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 257, 62, 256) 0           skip2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 257, 62, 256) 0           up_sampling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 257, 62, 64)  65600       dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "skip3 (Concatenate)             (None, 257, 62, 128) 0           conv2d_6[0][0]                   \n",
      "                                                                 conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 257, 62, 128) 0           skip3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 257, 62, 128) 0           up_sampling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 257, 62, 3)   1539        dropout_5[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 633,635\n",
      "Trainable params: 633,635\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import RMSprop, Adam\n",
    "opt = RMSprop( learning_rate=0.001, rho=0.9, momentum=0.0, epsilon=1e-07, centered=False,name='RMSprop')\n",
    "autoencoder = Model(input_img, autoencoder(input_img))\n",
    "autoencoder.compile(loss='mse', optimizer = opt, metrics=['accuracy'])\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.optimizers import SGD\n",
    "# opt = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "# autoencoder = Model(input_img, autoencoder(input_img))\n",
    "# autoencoder.compile(loss='categorical_crossentropy', optimizer = opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Architecture 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.layers as layers\n",
    "import keras.models as models\n",
    "from keras.initializers import orthogonal\n",
    "\n",
    "\n",
    "def Conv2DLayer(x, filters, kernel, strides, padding, block_id, kernel_init=orthogonal()):\n",
    "    prefix = f'block_{block_id}_'\n",
    "    x = layers.Conv2D(filters, kernel_size=kernel, strides=strides, padding=padding,\n",
    "                      kernel_initializer=kernel_init, name=prefix+'conv')(x)\n",
    "    x = layers.LeakyReLU(name=prefix+'lrelu')(x)\n",
    "    x = layers.Dropout(0.2, name=prefix+'drop')((x))\n",
    "    x = layers.BatchNormalization(name=prefix+'conv_bn')(x)\n",
    "    return x\n",
    "\n",
    "def Transpose_Conv2D(x, filters, kernel, strides, padding, block_id, kernel_init=orthogonal()):\n",
    "    prefix = f'block_{block_id}_'\n",
    "    x = layers.Conv2DTranspose(filters, kernel_size=kernel, strides=strides, padding=padding,\n",
    "                               kernel_initializer=kernel_init, name=prefix+'de-conv')(x)\n",
    "    x = layers.LeakyReLU(name=prefix+'lrelu')(x)\n",
    "    x = layers.Dropout(0.2, name=prefix+'drop')((x))\n",
    "    x = layers.BatchNormalization(name=prefix+'conv_bn')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "\n",
    "def AutoEncdoer(input_shape):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    \n",
    "    # 256 x 256\n",
    "    conv1 = Conv2DLayer(inputs, 64, 3, strides=1, padding='same', block_id=1)\n",
    "    conv2 = Conv2DLayer(conv1, 64, 3, strides=1, padding='same', block_id=2)\n",
    "    \n",
    "    # 128 x 128\n",
    "    conv3 = Conv2DLayer(conv2, 128, 5, strides=1, padding='same', block_id=3)\n",
    "    \n",
    "    # 64 x 64\n",
    "    conv4 = Conv2DLayer(conv3, 128, 3, strides=1, padding='same', block_id=4)\n",
    "    conv5 = Conv2DLayer(conv4, 256, 5, strides=1, padding='same', block_id=5)\n",
    "    \n",
    "    # 32 x 32\n",
    "    conv6 = Conv2DLayer(conv5, 512, 3, strides=1, padding='same', block_id=6)\n",
    "    \n",
    "    # 16 x 16\n",
    "    deconv1 = Transpose_Conv2D(conv6, 512, 3, strides=1, padding='same', block_id=7)\n",
    "    \n",
    "    # 32 x 32\n",
    "    skip1 = layers.concatenate([deconv1, conv5], name='skip1')\n",
    "    conv7 = Conv2DLayer(skip1, 256, 3, strides=1, padding='same', block_id=8)\n",
    "    deconv2 = Transpose_Conv2D(conv7, 128, 3, strides=1, padding='same', block_id=9)\n",
    "    \n",
    "    # 64 x 64\n",
    "    skip2 = layers.concatenate([deconv2, conv3], name='skip2')\n",
    "    conv8 = Conv2DLayer(skip2, 128, 5, strides=1, padding='same', block_id=10)\n",
    "    deconv3 = Transpose_Conv2D(conv8, 64, 3, strides=1, padding='same', block_id=11)\n",
    "    \n",
    "    # 128 x 128\n",
    "    skip3 = layers.concatenate([deconv3, conv2], name='skip3')\n",
    "    conv9 = Conv2DLayer(skip3, 64, 5, strides=1, padding='same', block_id=12)\n",
    "    deconv4 = Transpose_Conv2D(conv9, 64, 3, strides=1, padding='same', block_id=13)\n",
    "    \n",
    "    # 256 x 256\n",
    "    skip3 = layers.concatenate([deconv4, conv1])\n",
    "    conv10 = layers.Conv2D(3, 3, strides=1, padding='same', activation='sigmoid',\n",
    "                       kernel_initializer=orthogonal(), name='final_conv')(skip3)\n",
    "\n",
    "    \n",
    "    return models.Model(inputs=inputs, outputs=conv10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD, Adam, RMSprop \n",
    "opt = RMSprop( learning_rate=0.001, rho=0.9, momentum=0.0, epsilon=1e-07, centered=False,name='RMSprop')\n",
    "# opt = Adam(lr=0.001)\n",
    "# opt = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "autoencoder = AutoEncdoer((ROW,COL, 3))\n",
    "autoencoder.compile(optimizer=opt, loss=['mae','mse'], metrics=['mse','accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 257, 62, 3)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block_1_conv (Conv2D)           (None, 257, 62, 64)  1792        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block_1_lrelu (LeakyReLU)       (None, 257, 62, 64)  0           block_1_conv[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_1_drop (Dropout)          (None, 257, 62, 64)  0           block_1_lrelu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_1_conv_bn (BatchNormaliza (None, 257, 62, 64)  256         block_1_drop[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_2_conv (Conv2D)           (None, 257, 62, 64)  36928       block_1_conv_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2_lrelu (LeakyReLU)       (None, 257, 62, 64)  0           block_2_conv[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_2_drop (Dropout)          (None, 257, 62, 64)  0           block_2_lrelu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2_conv_bn (BatchNormaliza (None, 257, 62, 64)  256         block_2_drop[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_3_conv (Conv2D)           (None, 257, 62, 128) 204928      block_2_conv_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_3_lrelu (LeakyReLU)       (None, 257, 62, 128) 0           block_3_conv[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_3_drop (Dropout)          (None, 257, 62, 128) 0           block_3_lrelu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3_conv_bn (BatchNormaliza (None, 257, 62, 128) 512         block_3_drop[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_4_conv (Conv2D)           (None, 257, 62, 128) 147584      block_3_conv_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4_lrelu (LeakyReLU)       (None, 257, 62, 128) 0           block_4_conv[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_4_drop (Dropout)          (None, 257, 62, 128) 0           block_4_lrelu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_4_conv_bn (BatchNormaliza (None, 257, 62, 128) 512         block_4_drop[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_5_conv (Conv2D)           (None, 257, 62, 256) 819456      block_4_conv_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_5_lrelu (LeakyReLU)       (None, 257, 62, 256) 0           block_5_conv[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_5_drop (Dropout)          (None, 257, 62, 256) 0           block_5_lrelu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_5_conv_bn (BatchNormaliza (None, 257, 62, 256) 1024        block_5_drop[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_6_conv (Conv2D)           (None, 257, 62, 512) 1180160     block_5_conv_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_6_lrelu (LeakyReLU)       (None, 257, 62, 512) 0           block_6_conv[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_6_drop (Dropout)          (None, 257, 62, 512) 0           block_6_lrelu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_6_conv_bn (BatchNormaliza (None, 257, 62, 512) 2048        block_6_drop[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_7_de-conv (Conv2DTranspos (None, 257, 62, 512) 2359808     block_6_conv_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_7_lrelu (LeakyReLU)       (None, 257, 62, 512) 0           block_7_de-conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_7_drop (Dropout)          (None, 257, 62, 512) 0           block_7_lrelu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_7_conv_bn (BatchNormaliza (None, 257, 62, 512) 2048        block_7_drop[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "skip1 (Concatenate)             (None, 257, 62, 768) 0           block_7_conv_bn[0][0]            \n",
      "                                                                 block_5_conv_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_8_conv (Conv2D)           (None, 257, 62, 256) 1769728     skip1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_8_lrelu (LeakyReLU)       (None, 257, 62, 256) 0           block_8_conv[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_8_drop (Dropout)          (None, 257, 62, 256) 0           block_8_lrelu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_8_conv_bn (BatchNormaliza (None, 257, 62, 256) 1024        block_8_drop[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_9_de-conv (Conv2DTranspos (None, 257, 62, 128) 295040      block_8_conv_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_9_lrelu (LeakyReLU)       (None, 257, 62, 128) 0           block_9_de-conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_9_drop (Dropout)          (None, 257, 62, 128) 0           block_9_lrelu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_9_conv_bn (BatchNormaliza (None, 257, 62, 128) 512         block_9_drop[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "skip2 (Concatenate)             (None, 257, 62, 256) 0           block_9_conv_bn[0][0]            \n",
      "                                                                 block_3_conv_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_10_conv (Conv2D)          (None, 257, 62, 128) 819328      skip2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_10_lrelu (LeakyReLU)      (None, 257, 62, 128) 0           block_10_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_10_drop (Dropout)         (None, 257, 62, 128) 0           block_10_lrelu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_10_conv_bn (BatchNormaliz (None, 257, 62, 128) 512         block_10_drop[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_11_de-conv (Conv2DTranspo (None, 257, 62, 64)  73792       block_10_conv_bn[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_11_lrelu (LeakyReLU)      (None, 257, 62, 64)  0           block_11_de-conv[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_11_drop (Dropout)         (None, 257, 62, 64)  0           block_11_lrelu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_11_conv_bn (BatchNormaliz (None, 257, 62, 64)  256         block_11_drop[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "skip3 (Concatenate)             (None, 257, 62, 128) 0           block_11_conv_bn[0][0]           \n",
      "                                                                 block_2_conv_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_12_conv (Conv2D)          (None, 257, 62, 64)  204864      skip3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_12_lrelu (LeakyReLU)      (None, 257, 62, 64)  0           block_12_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_12_drop (Dropout)         (None, 257, 62, 64)  0           block_12_lrelu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_12_conv_bn (BatchNormaliz (None, 257, 62, 64)  256         block_12_drop[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_13_de-conv (Conv2DTranspo (None, 257, 62, 64)  36928       block_12_conv_bn[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_13_lrelu (LeakyReLU)      (None, 257, 62, 64)  0           block_13_de-conv[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_13_drop (Dropout)         (None, 257, 62, 64)  0           block_13_lrelu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_13_conv_bn (BatchNormaliz (None, 257, 62, 64)  256         block_13_drop[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 257, 62, 128) 0           block_13_conv_bn[0][0]           \n",
      "                                                                 block_1_conv_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "final_conv (Conv2D)             (None, 257, 62, 3)   3459        concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 7,963,267\n",
      "Trainable params: 7,958,531\n",
      "Non-trainable params: 4,736\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "from tensorflow.python.keras.saving import saving_utils as _saving_utils\n",
    "from tensorflow.python.framework import convert_to_constants as convert_variables_to_constants_v2\n",
    "\n",
    "print(tf.version.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    }
   ],
   "source": [
    "PERIOD = 5\n",
    "\n",
    "# Include the epoch in the file name (uses `str.format`)\n",
    "checkpoint_path = \"modelcheckpoints/cp-{epoch:04d}.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create a callback that saves the model's weights every 10 epochs\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path, \n",
    "    verbose=1, \n",
    "    save_weights_only=True,\n",
    "    period=PERIOD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the weights using the `checkpoint_path` format\n",
    "autoencoder.save_weights(checkpoint_path.format(epoch=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'modelcheckpoints\\\\cp-0000.ckpt'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'modelcheckpoints'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x1d95c05c888>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the previously saved weights\n",
    "autoencoder.load_weights(latest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCallback(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, autoencoder_train\n",
    "                     ,epoch, logs=None):\n",
    "        rate = 16000\n",
    "        for j in range(5):\n",
    "            r_num = random.randint(0, nb_test_samples-1)\n",
    "            test_file = test_image[r_num]\n",
    "            img_test = np.load(test_file)\n",
    "            img_test = img_test/255\n",
    "            img_test = img_test.reshape(-1, ROW,COL,3)\n",
    "            decoded_imgs = autoencoder.predict(img_test) #predict\n",
    "            decoded_imgs = decoded_imgs.reshape(ROW,COL,3)\n",
    "            decoded_imgs = decoded_imgs*255\n",
    "            decoded_imgs = decoded_imgs.astype(np.int16)\n",
    "            data = recoverSignalFromSpectrogram(decoded_imgs)\n",
    "            scipy.io.wavfile.write('./'+\"predict_{}\".format(j)+'.wav', rate, data)\n",
    "        autoencoder.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1400/1400 [==============================] - 13646s 10s/step - loss: 0.0886 - mse: 0.0338 - accuracy: 0.9122 - val_loss: 0.0965 - val_mse: 0.0335 - val_accuracy: 0.8752\n",
      "Epoch 2/30\n",
      "1400/1400 [==============================] - 13801s 10s/step - loss: 0.0781 - mse: 0.0270 - accuracy: 0.9265 - val_loss: 0.0957 - val_mse: 0.0326 - val_accuracy: 0.8777\n",
      "Epoch 3/30\n",
      "1311/1400 [===========================>..] - ETA: 33:34 - loss: 0.0770 - mse: 0.0265 - accuracy: 0.9277"
     ]
    }
   ],
   "source": [
    "for i in range(len(train_batch_size)):\n",
    "    autoencoder_train = autoencoder.fit(data_gen_train(train_batch_size[i]),\n",
    "                                    epochs= epochs,\n",
    "                                    verbose=1,\n",
    "                                    steps_per_epoch= nb_train_samples // train_batch_size[i],\n",
    "                                    validation_data= data_gen_test(test_batch_size[i]),\n",
    "                                    validation_steps=nb_test_samples // test_batch_size[i],\n",
    "                                    callbacks=[cp_callback,CustomCallback()])\n",
    "    pyplot.subplot(211)\n",
    "    pyplot.title('Loss')\n",
    "    pyplot.plot(autoencoder_train.history['loss'], label='train')\n",
    "    pyplot.plot(autoencoder_train.history['val_loss'], label='test')\n",
    "    pyplot.legend()\n",
    "    pyplot.show()\n",
    "    pyplot.subplot(212)\n",
    "    pyplot.title('Mean Squared Error')\n",
    "    pyplot.plot(autoencoder_train.history['mean_squared_error'], label='train')\n",
    "    pyplot.plot(autoencoder_train.history['val_mean_squared_error'], label='test')\n",
    "    pyplot.legend()\n",
    "    pyplot.show()\n",
    "    # list all data in history\n",
    "    print(autoencoder_train.history.keys())\n",
    "    # summarize history for accuracy\n",
    "    plt.plot(autoencoder_train.history['accuracy'])\n",
    "    plt.plot(autoencoder_train.history['val_accuracy'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "#     # summarize history for loss\n",
    "#     plt.plot(autoencoder_train.history['loss'])\n",
    "#     plt.plot(autoencoder_train.history['val_loss'])\n",
    "#     plt.title('model loss')\n",
    "#     plt.ylabel('loss')\n",
    "#     plt.xlabel('epoch')\n",
    "#     plt.legend(['train', 'test'], loc='upper left')\n",
    "#     plt.show()\n",
    "\n",
    "# evaluate the model=\n",
    "#     _, train_acc = autoencoder.evaluate(data_gen_train(train_batch_size[i]), verbose=0)\n",
    "#     _, test_acc = autoencoder.evaluate(data_gen_test(test_batch_size[i]), verbose=0)\n",
    "#     print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))\n",
    "# plot training history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
